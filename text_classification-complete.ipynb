{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Out to Sea was a great movie. I expected comed...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This may not be the worst movie ever made, but...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It has been since 1972 that I saw this movie a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>As so many others have written, this is a wond...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Rounding out the 1929-30 all-talkie \"Our Gang\"...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Out to Sea was a great movie. I expected comed...  positive\n",
       "1  This may not be the worst movie ever made, but...  negative\n",
       "2  It has been since 1972 that I saw this movie a...  positive\n",
       "3  As so many others have written, this is a wond...  positive\n",
       "4  Rounding out the 1929-30 all-talkie \"Our Gang\"...  negative"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/IMDB_training.csv'\n",
    "\n",
    "# reading the csv file into a pandas dataframe\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# drop Unnamed Column\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative reviews: 15079\n",
      "positive reviews: 14921\n"
     ]
    }
   ],
   "source": [
    "# what's the ratio between positive and negative reviews?\n",
    "neg_count = len(df[df['sentiment']=='negative'])\n",
    "print('negative reviews:', neg_count)\n",
    "\n",
    "pos_count = len(df[df['sentiment']=='positive'])\n",
    "print('positive reviews:', pos_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create smaller sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(5000)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 3500\n",
      "test: 1500\n"
     ]
    }
   ],
   "source": [
    "# split test and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "print('training:', len(train_x))\n",
    "print('test:', len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use regex to remove punctuation and lowercase everything\n",
    "\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "train_x_clean = preprocess_reviews(train_x)\n",
    "test_x_clean = preprocess_reviews(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 37111\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "\n",
    "# apply vectorizer to training dataset\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x_clean)\n",
    "\n",
    "# apply vectorizer to test dataset\n",
    "test_x_vectors = vectorizer.transform(test_x_clean)\n",
    "\n",
    "print('word count:', len(vectorizer.get_feature_names()))\n",
    "print(train_x_vectors.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This seemed really similar to the CHILD'S PLAY movies except so much worse. A lawyer tries to save a criminal, who was convicted of killing his son, from execution. She fails. The lawyer's daughter then finds a puppet that the killer had buried with his son and is immediately attached to it. Then after several people are seriously injured they find the little girl secretly talking to the doll saying that she didn't hurt anyone. Throughout this movie I found myself asking myself ' why am I watching this cheeze?' over and over. The end sucked so bad that I went and watched the Disney cartoon version right after and slept with the light on.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=.5, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "\n",
    "# fit training data\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "# have a look at a test data sample\n",
    "print(test_x.values[6])\n",
    "\n",
    "# use classifier to predict sentiment of sample\n",
    "clf_svm.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "# use classifier to predict sentiment\n",
    "clf_dec.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression() # use: max_iter=1000 to avoid error\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "# use classifier to predict sentiment\n",
    "clf_log.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf_rdg = RidgeClassifier(alpha = 3, solver = 'sag', normalize = True, tol = 0.0001)\n",
    "clf_rdg.fit(train_x_vectors, train_y)\n",
    "\n",
    "# use classifier to predict sentiment\n",
    "clf_rdg.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.8486666666666667\n",
      "DEC: 0.6666666666666666\n",
      "LOG: 0.8406666666666667\n",
      "RDG: 0.8446666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('SVM:', accuracy_score(test_y, clf_svm.predict(test_x_vectors)))\n",
    "print('DEC:', accuracy_score(test_y, clf_dec.predict(test_x_vectors)))\n",
    "print('LOG:', accuracy_score(test_y, clf_log.predict(test_x_vectors)))\n",
    "print('RDG:', accuracy_score(test_y, clf_rdg.predict(test_x_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.8303571428571429\n",
      "DEC: 0.6635514018691588\n",
      "LOG: 0.8146766169154229\n",
      "RDG: 0.8595505617977528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print('SVM:', precision_score(test_y, clf_svm.predict(test_x_vectors), pos_label=\"positive\"))\n",
    "print('DEC:', precision_score(test_y, clf_dec.predict(test_x_vectors), pos_label=\"positive\"))\n",
    "print('LOG:', precision_score(test_y, clf_log.predict(test_x_vectors), pos_label=\"positive\"))\n",
    "print('RDG:', precision_score(test_y, clf_rdg.predict(test_x_vectors), pos_label=\"positive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.8738255033557047\n",
      "DEC: 0.6671140939597315\n",
      "LOG: 0.8791946308724832\n",
      "RDG: 0.8214765100671141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('SVM:', recall_score(test_y, clf_svm.predict(test_x_vectors), pos_label=\"positive\"))\n",
    "print('DEC:', recall_score(test_y, clf_dec.predict(test_x_vectors), pos_label=\"positive\"))\n",
    "print('LOG:', recall_score(test_y, clf_log.predict(test_x_vectors), pos_label=\"positive\"))\n",
    "print('RDG:', recall_score(test_y, clf_rdg.predict(test_x_vectors), pos_label=\"positive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84568321 0.85153695]\n",
      "[0.66799469 0.66532798]\n",
      "[0.83528601 0.84570691]\n",
      "[0.84899546 0.84008236]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=['negative', 'positive']))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=['negative', 'positive']))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=['negative', 'positive']))\n",
    "print(f1_score(test_y, clf_rdg.predict(test_x_vectors), average=None, labels=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[622 133]\n",
      " [ 94 651]]\n",
      "[[503 252]\n",
      " [248 497]]\n",
      "[[606 149]\n",
      " [ 90 655]]\n",
      "[[655 100]\n",
      " [133 612]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_y, clf_svm.predict(test_x_vectors)))\n",
    "print(confusion_matrix(test_y, clf_dec.predict(test_x_vectors)))\n",
    "print(confusion_matrix(test_y, clf_log.predict(test_x_vectors)))\n",
    "print(confusion_matrix(test_y, clf_rdg.predict(test_x_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter testing with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test set\n",
    "test_set = ['great show', 'bad movie, do not watch', 'what a waste of time']\n",
    "\n",
    "# transform to sparse matrix\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "# use logistic regression classifier to predict sentiment\n",
    "clf_log.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model with pickle for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "classifier_filename = 'category_classifier_YOURNAME.pkl' ##change YOURNAME\n",
    "vectorizer_filename = 'category_vectorizer_YOURNAME.pkl' ##change YOURNAME\n",
    "\n",
    "with open(classifier_filename, 'wb') as f:\n",
    "    pickle.dump(clf_rdg, f) ##change rdg to whatever model you choose to submit\n",
    "    \n",
    "with open(vectorizer_filename, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
